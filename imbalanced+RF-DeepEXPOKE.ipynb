{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "#import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYDataFileName = \"42p_82894samples_02-23-24_incidence_XY.txt\";\n",
    "dataFolderPath = \"/Users/adsriram98/Documents/PARK_LAB/PRS_calc/data\";\n",
    "mypara = {'num_epochs': 50, 'batch_size': 20}\n",
    "'''\n",
    "Run MGM\n",
    "Note: MGM was implemented in Java and the following Python APIs call the Java implementation.\n",
    "Please restart the Python program after encountering a JVM problem.\n",
    "The format of the input data file must be \".txt\" in which columns are separated by \"\\t\" and it should also include the response variables.\n",
    "Here is what the input data should look like:\n",
    "X1 X2 ... Xp\n",
    "1  1  ... 1\n",
    "'''\n",
    "# import the MGM package\n",
    "#from MGM.MGM import MGM\n",
    "# Initialize a MGM object\n",
    "#mgm = MGM();\n",
    "'''\n",
    "Run MGM\n",
    "Parameters:\n",
    "    dataFolderPath: the directory that stores the input data.\n",
    "    DataFileName: the name of the input data.\n",
    "    lambda_continuous_continuous: the panalty value 'lambda' set for the associations whose two end variables are continuous.\n",
    "    lamda_continuous_discrete: the panalty value 'lambda' set for the associations whose one end variable is continuous and the other is discrete.\n",
    "    lamda_discrete_discrete: the panalty value 'lambda' set for the associations whose two end variables are discrete.\n",
    "    \n",
    "Return:\n",
    "    mgmOutputFile: a tuple, where the first file contains all the selected associations and the second file contains the corresponding likelihoods.\n",
    "'''\n",
    "#mgmOutputFile = mgm.runMGM(dataFolderPath, XYDataFileName,lambda_continuous_continuous = 0.3, lamda_continuous_discrete = 0.3, lamda_discrete_discrete = 0.3);\n",
    "\"\"\"\n",
    "MGM uses the Python package Jpype to call MGM's Java implementation.\n",
    "According to Jpype documents, it says \"Due to limitations in the JPype, \n",
    "it is not possible to restart the JVM after being terminated.\"\n",
    "Therefore, please restart the Python kernel if you encounter an OSError (i.e., \"OSError: JVM cannot be restarted\").\n",
    "\"\"\"\n",
    "#print(\"MGM's output was saved as the following file:\");\n",
    "#print(mgmOutputFile[0]);\n",
    "#print(\"The likelihood values were saved as the following file:\");\n",
    "#print(mgmOutputFile[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Generate knockoff data using one of two methods: ISEE Omega and Cholesky_LU.\n",
    "The code for generating ISEE Omega knockoff is implemented using R. Please make sure your computer has R installed.\n",
    "'''\n",
    "from DL.knockoff.KnockoffGenerator import KnockoffGenerator;\n",
    "generator = KnockoffGenerator();\n",
    "\n",
    "dataFolderPath = \"/Users/adsriram98/Documents/PARK_LAB/PRS_calc/data\";\n",
    "DataFileName = \"42p_82894samples_02-23-24_incidence_X.txt\"\n",
    "knockoffFilePath = generator.CholLuKnockoff(dataFolderPath, DataFileName,sep=\"\\t\");\n",
    "\n",
    "# #If want to generate ISEE Omega knockoff, please set the ISEE code path and R home environment.\n",
    "# generator.set_ISEE_path(\"/absolute_path_of_DAG_DeepVASE\");#/home/user/DAG_DeepVASE/\n",
    "# generator.set_R_home('absolute_path_to_directory_where_r_is_installed');#e.g.,/home/user/lib/R\n",
    "#knockoffFilePath = generator.ISEEKnockoff(dataFolderPath, DataFileName,sep=\"\\t\");\n",
    "\n",
    "print(\"The newly generated knockoff file is named as:\");\n",
    "print(knockoffFilePath);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XKnockoffData = pd.read_csv(knockoffFilePath,sep=\"\\t\"); #for stat knockoffs\n",
    "#XKnockoffData = pd.read_csv(\"/Users/adsriram98/Documents/PARK_LAB/PRS_calc/data/02-22-24-PRSknockoffs-incidence.csv\", sep=\",\") #for PRS knockoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''''\n",
    "# After generating the knockoff data, run DNN\n",
    "\n",
    "dataFolderPath = \"/Users/adsriram98/Documents/PARK_LAB/PRS_calc/data\"\n",
    "XKnockoffData = pd.read_csv(knockoffFilePath,sep=\"\\t\"); #for stat knockoffs\n",
    "#XKnockoffData = pd.read_csv(\"/Users/adsriram98/Documents/PARK_LAB/PRS_calc/data/06-07-24-onlyIncidenceAHD_PRSknockoffs.csv\", sep=\",\") #for PRS knockoffs\n",
    "\n",
    "YDataFileName = \"42p_82894samples_02-23-24_incidence_Y.txt\";\n",
    "Ydata = pd.read_csv(dataFolderPath+os.path.sep+YDataFileName,sep=\"\\t\");\n",
    "\n",
    "XKValues = XKnockoffData.values;\n",
    "YValues = Ydata.values;\n",
    "    \n",
    "pNum = int(XKValues.shape[1] / 2);\n",
    "n = XKValues.shape[0];\n",
    "print(XKValues.shape);\n",
    "print(YValues.shape);\n",
    "print(pNum);\n",
    "    \n",
    "XOrigin = XKValues[:, 0:pNum];\n",
    "knockoff = XKValues[:, pNum:];\n",
    "\n",
    "X3DTrain = np.zeros((n, pNum, 2));\n",
    "X3DTrain[:, :, 0] = XOrigin;\n",
    "X3DTrain[:, :, 1] = knockoff;\n",
    "labelTrain = YValues;\n",
    "    \n",
    "coeff = 0.05 * np.sqrt(2.0 * np.log(pNum) / n);\n",
    "\n",
    "nOutputs = Ydata.shape[1];\n",
    "\n",
    "#Save the DNN output to the following directory.\n",
    "resultDir = dataFolderPath+os.path.sep+'02_23_predictor_STATKO_DNN_result/'; #or PRSKO; change the knockoff naming and directory accordingly\n",
    "if not os.path.exists(resultDir):\n",
    "    os.makedirs(resultDir);\n",
    "    \n",
    "from DL.DNN.DNN import DNN;\n",
    "#from sklearn.model_selection import cross_val_score;\n",
    "#import tensorflow as tf;\n",
    "\n",
    "paralabel = \"epo\" + str(mypara['num_epochs']) + \"batch\" + str(mypara['batch_size']);\n",
    "print(paralabel);\n",
    "\n",
    "dnn = DNN(output_layer_activation='sigmoid', output_loss = 'binary_crossentropy',\n",
    "          num_epochs = mypara['num_epochs'],\n",
    "          batch_size = mypara['batch_size']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3DTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3DTrain.shape\n",
    "labelTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelTrain\n",
    "XKValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf;\n",
    "#scores= cross_val_score(model, X3DTrain, labelTrain, cv=5)\n",
    "Ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dataFolderPath +os.path.sep+paralabel):\n",
    "        os.makedirs(dataFolderPath +os.path.sep+paralabel)\n",
    "        print(f\"Directory '{dataFolderPath +os.path.sep+paralabel}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#yhat3DTrain=model.predict(X3DTrain)\n",
    "#pd.DataFrame(yhat3DTrain).to_csv(dataFolderPath +os.path.sep+paralabel+os.path.sep+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef, precision_recall_curve, average_precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imbalanced_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labelTrain), y=labelTrain.ravel())\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data = X3DTrain\n",
    "    labels = labelTrain\n",
    "    header_info = \"Your header information here\"\n",
    "    return data, labels, header_info\n",
    "\n",
    "def create_model():\n",
    "    dnn = DNN(output_layer_activation='sigmoid', output_loss='binary_crossentropy',\n",
    "              num_epochs=mypara['num_epochs'], batch_size=mypara['batch_size'])\n",
    "    model = dnn.build_DNN(pNum, nOutputs, coeff)\n",
    "    callback = DNN.Job_finish_Callback(resultDir, pNum)\n",
    "    return model, callback\n",
    "\n",
    "def calculate_optimal_threshold(y_true, y_probs):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "def train_and_evaluate_xgboost(data_train, labels_train, data_test, labels_test, metrics_vector_xgb):\n",
    "    data_train_flattened = data_train.reshape(data_train.shape[0], -1)\n",
    "    data_test_flattened = data_test.reshape(data_test.shape[0], -1)\n",
    "\n",
    "    dtrain = xgb.DMatrix(data_train_flattened, label=labels_train)\n",
    "    dtest = xgb.DMatrix(data_test_flattened, label=labels_test)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'scale_pos_weight': class_weights[1] / class_weights[0]\n",
    "    }\n",
    "    num_rounds = 100\n",
    "\n",
    "    bst = xgb.train(params, dtrain, num_rounds)\n",
    "    preds_prob = bst.predict(dtest)\n",
    "    auc_score = roc_auc_score(labels_test, preds_prob)\n",
    "    precision, recall, _ = precision_recall_curve(labels_test, preds_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    optimal_threshold = calculate_optimal_threshold(labels_test, preds_prob)\n",
    "    mcc = matthews_corrcoef(labels_test, (preds_prob > optimal_threshold).astype(int))\n",
    "\n",
    "    metrics_vector_xgb.append([auc_score, pr_auc, mcc])\n",
    "\n",
    "def train_and_evaluate_rf(data_train, labels_train, data_test, labels_test, metrics_vector_rf):\n",
    "    data_train_flattened = data_train.reshape(data_train.shape[0], -1)\n",
    "    data_test_flattened = data_test.reshape(data_test.shape[0], -1)\n",
    "\n",
    "    rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100)\n",
    "    rf_model.fit(data_train_flattened, labels_train.ravel())\n",
    "    preds_prob = rf_model.predict_proba(data_test_flattened)[:, 1]\n",
    "    auc_score = roc_auc_score(labels_test, preds_prob)\n",
    "    precision, recall, _ = precision_recall_curve(labels_test, preds_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    optimal_threshold = calculate_optimal_threshold(labels_test, preds_prob)\n",
    "    mcc = matthews_corrcoef(labels_test, (preds_prob > optimal_threshold).astype(int))\n",
    "\n",
    "    metrics_vector_rf.append([auc_score, pr_auc, mcc])\n",
    "\n",
    "def train_and_evaluate_lr(data_train, labels_train, data_test, labels_test, metrics_vector_lr):\n",
    "    data_train_flattened = data_train.reshape(data_train.shape[0], -1)\n",
    "    data_test_flattened = data_test.reshape(data_test.shape[0], -1)\n",
    "\n",
    "    lr_model = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "    lr_model.fit(data_train_flattened, labels_train.ravel())\n",
    "    preds_prob = lr_model.predict_proba(data_test_flattened)[:, 1]\n",
    "    auc_score = roc_auc_score(labels_test, preds_prob)\n",
    "    precision, recall, _ = precision_recall_curve(labels_test, preds_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    optimal_threshold = calculate_optimal_threshold(labels_test, preds_prob)\n",
    "    mcc = matthews_corrcoef(labels_test, (preds_prob > optimal_threshold).astype(int))\n",
    "\n",
    "    metrics_vector_lr.append([auc_score, pr_auc, mcc])\n",
    "    \n",
    "def train_and_evaluate_svc(data_train, labels_train, data_test, labels_test, metrics_vector_svc):\n",
    "    data_train_flattened = data_train.reshape(data_train.shape[0], -1)\n",
    "    data_test_flattened = data_test.reshape(data_test.shape[0], -1)\n",
    "\n",
    "    svc_model = LinearSVC(class_weight='balanced', max_iter=5000)\n",
    "    calibrated_svc = CalibratedClassifierCV(svc_model, method='sigmoid', cv=5)\n",
    "    calibrated_svc.fit(data_train_flattened, labels_train.ravel())\n",
    "    preds_prob = calibrated_svc.predict_proba(data_test_flattened)[:, 1]\n",
    "    auc_score = roc_auc_score(labels_test, preds_prob)\n",
    "    precision, recall, _ = precision_recall_curve(labels_test, preds_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    optimal_threshold = calculate_optimal_threshold(labels_test, preds_prob)\n",
    "    mcc = matthews_corrcoef(labels_test, (preds_prob > optimal_threshold).astype(int))\n",
    "\n",
    "    metrics_vector_svc.append([auc_score, pr_auc, mcc])\n",
    "\n",
    "def train_and_evaluate_knn(data_train, labels_train, data_test, labels_test, metrics_vector_knn):\n",
    "    data_train_flattened = data_train.reshape(data_train.shape[0], -1)\n",
    "    data_test_flattened = data_test.reshape(data_test.shape[0], -1)\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(data_train_flattened, labels_train.ravel())\n",
    "    preds_prob = knn_model.predict_proba(data_test_flattened)[:, 1]\n",
    "    auc_score = roc_auc_score(labels_test, preds_prob)\n",
    "    precision, recall, _ = precision_recall_curve(labels_test, preds_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    optimal_threshold = calculate_optimal_threshold(labels_test, preds_prob)\n",
    "    mcc = matthews_corrcoef(labels_test, (preds_prob > optimal_threshold).astype(int))\n",
    "\n",
    "    metrics_vector_knn.append([auc_score, pr_auc, mcc])\n",
    "\n",
    "def train_and_evaluate_model(model, data_train, labels_train, data_test, labels_test, metrics_vector):\n",
    "    smote = SMOTE(sampling_strategy='auto')\n",
    "    under_sampler = RandomUnderSampler(sampling_strategy='auto')\n",
    "    \n",
    "    resampling_pipeline = imbalanced_pipeline([\n",
    "        ('smote', smote),\n",
    "        ('under', under_sampler)\n",
    "    ])\n",
    "    \n",
    "    data_train_resampled, labels_train_resampled = resampling_pipeline.fit_resample(data_train.reshape(data_train.shape[0], -1), labels_train.ravel())\n",
    "    data_train_resampled = data_train_resampled.reshape(data_train_resampled.shape[0], pNum, 2)\n",
    "    \n",
    "    dnn.train_DNN(model, data_train_resampled, labels_train_resampled, callback, class_weights=class_weights)\n",
    "    yhat_test_prob = model.predict(data_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels_test, yhat_test_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    yhat_test = (yhat_test_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "    true_values = pd.Series(labels_test.ravel())\n",
    "    predicted_values = pd.Series(yhat_test.ravel())\n",
    "    label_encoder = LabelEncoder()\n",
    "    true_values = label_encoder.fit_transform(true_values)\n",
    "    predicted_values = label_encoder.transform(predicted_values)\n",
    "\n",
    "    cm = confusion_matrix(true_values, predicted_values)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = accuracy_score(true_values, predicted_values)\n",
    "    sensitivity = recall_score(true_values, predicted_values)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = precision_score(true_values, predicted_values)\n",
    "    f1 = f1_score(true_values, predicted_values)\n",
    "    mcc = matthews_corrcoef(true_values, predicted_values)\n",
    "    precision_recall_auc = average_precision_score(true_values, yhat_test_prob)\n",
    "    \n",
    "    metrics = [accuracy, sensitivity, specificity, precision, f1, roc_auc, precision_recall_auc, mcc, i]\n",
    "    metrics_vector.append(metrics)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_folds = 10\n",
    "    data, labels, header_info = load_data()\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "    metrics_vector = []\n",
    "    metrics_vector_xgb = []\n",
    "    metrics_vector_rf = []\n",
    "    metrics_vector_lr = []\n",
    "    metrics_vector_svc = []\n",
    "    metrics_vector_knn = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(data, labels)):\n",
    "        print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "        data_train, labels_train = data[train_idx], labels[train_idx]\n",
    "        data_test, labels_test = data[test_idx], labels[test_idx]\n",
    "\n",
    "        model, callback = create_model()\n",
    "        train_and_evaluate_model(model, data_train, labels_train, data_test, labels_test, metrics_vector)\n",
    "        train_and_evaluate_xgboost(data_train, labels_train, data_test, labels_test, metrics_vector_xgb)\n",
    "        train_and_evaluate_rf(data_train, labels_train, data_test, labels_test, metrics_vector_rf)\n",
    "        train_and_evaluate_lr(data_train, labels_train, data_test, labels_test, metrics_vector_lr)\n",
    "        train_and_evaluate_svc(data_train, labels_train, data_test, labels_test, metrics_vector_svc)\n",
    "        train_and_evaluate_knn(data_train, labels_train, data_test, labels_test, metrics_vector_knn)\n",
    "\n",
    "    mean_auc_xgb = np.mean([x[0] for x in metrics_vector_xgb])\n",
    "    mean_pr_auc_xgb = np.mean([x[1] for x in metrics_vector_xgb])\n",
    "    mean_mcc_xgb = np.mean([x[2] for x in metrics_vector_xgb])\n",
    "\n",
    "    mean_auc_rf = np.mean([x[0] for x in metrics_vector_rf])\n",
    "    mean_pr_auc_rf = np.mean([x[1] for x in metrics_vector_rf])\n",
    "    mean_mcc_rf = np.mean([x[2] for x in metrics_vector_rf])\n",
    "\n",
    "    mean_auc_lr = np.mean([x[0] for x in metrics_vector_lr])\n",
    "    mean_pr_auc_lr = np.mean([x[1] for x in metrics_vector_lr])\n",
    "    mean_mcc_lr = np.mean([x[2] for x in metrics_vector_lr])\n",
    "\n",
    "    mean_auc_svc = np.mean([x[0] for x in metrics_vector_svc])\n",
    "    mean_pr_auc_svc = np.mean([x[1] for x in metrics_vector_svc])\n",
    "    mean_mcc_svc = np.mean([x[2] for x in metrics_vector_svc])\n",
    "\n",
    "    mean_auc_knn = np.mean([x[0] for x in metrics_vector_knn])\n",
    "    mean_pr_auc_knn = np.mean([x[1] for x in metrics_vector_knn])\n",
    "    mean_mcc_knn = np.mean([x[2] for x in metrics_vector_knn])\n",
    "\n",
    "    print(f\"Mean AUC XGBoost: {mean_auc_xgb}\")\n",
    "    print(f\"Mean prAUC XGBoost: {mean_pr_auc_xgb}\")\n",
    "    print(f\"Mean MCC XGBoost: {mean_mcc_xgb}\")\n",
    "\n",
    "    print(f\"Mean AUC Random Forest: {mean_auc_rf}\")\n",
    "    print(f\"Mean prAUC Random Forest: {mean_pr_auc_rf}\")\n",
    "    print(f\"Mean MCC Random Forest: {mean_mcc_rf}\")\n",
    "\n",
    "    print(f\"Mean AUC Logistic Regression: {mean_auc_lr}\")\n",
    "    print(f\"Mean prAUC Logistic Regression: {mean_pr_auc_lr}\")\n",
    "    print(f\"Mean MCC Logistic Regression: {mean_mcc_lr}\")\n",
    "\n",
    "    print(f\"Mean AUC LinearSVC: {mean_auc_svc}\")\n",
    "    print(f\"Mean prAUC LinearSVC: {mean_pr_auc_svc}\")\n",
    "    print(f\"Mean MCC LinearSVC: {mean_mcc_svc}\")\n",
    "\n",
    "    print(f\"Mean AUC KNeighborsClassifier: {mean_auc_knn}\")\n",
    "    print(f\"Mean prAUC KNeighborsClassifier: {mean_pr_auc_knn}\")\n",
    "    print(f\"Mean MCC KNeighborsClassifier: {mean_mcc_knn}\")\n",
    "\n",
    "    column_names = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'ROC_AUC', 'prAUC', 'MCC', 'Fold']\n",
    "    df = pd.DataFrame(metrics_vector, columns=column_names)\n",
    "\n",
    "    for i in range(len(metrics_vector)):\n",
    "        metrics_vector[i].extend(metrics_vector_xgb[i])\n",
    "        metrics_vector[i].extend(metrics_vector_rf[i])\n",
    "        metrics_vector[i].extend(metrics_vector_lr[i])\n",
    "        metrics_vector[i].extend(metrics_vector_svc[i])\n",
    "        metrics_vector[i].extend(metrics_vector_knn[i])\n",
    "\n",
    "    column_names.extend(['XGBoost_AUC', 'XGBoost_prAUC', 'XGBoost_MCC', 'RandomForest_AUC', 'RandomForest_prAUC', 'RandomForest_MCC', 'LogisticRegression_AUC', 'LogisticRegression_prAUC', 'LogisticRegression_MCC', 'LinearSVC_AUC', 'LinearSVC_prAUC', 'LinearSVC_MCC', 'KNeighbors_AUC', 'KNeighbors_prAUC', 'KNeighbors_MCC'])\n",
    "    df = pd.DataFrame(metrics_vector, columns=column_names)\n",
    "\n",
    "    mean_row = df.mean(axis=0)\n",
    "    mean_row['Fold'] = 'Mean'\n",
    "    df = pd.concat([df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "\n",
    "    df.to_csv(dataFolderPath + os.path.sep + paralabel + os.path.sep + \"02_23_SEPSISincidence_STATknockoffs_metrics_summary_dropout005_withXGB_RF_LR_SVC_KNN.csv\"); #or PRSKnockoffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
